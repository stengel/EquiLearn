{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningAgents import ReinforceAlgorithm\n",
    "from environmentModel import Model, AdversaryModes\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "adversaryProbs=torch.zeros(len(AdversaryModes))\n",
    "adversaryProbs[0]=1\n",
    "game = Model(totalDemand = 400, \n",
    "               tupleCosts = (57, 71),\n",
    "              totalStages = 25, adversaryProbs=adversaryProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0195, 0.0186, 0.0225, 0.0212, 0.0195, 0.0189, 0.0182, 0.0195, 0.0208,\n",
      "        0.0201, 0.0191, 0.0204, 0.0203, 0.0199, 0.0209, 0.0205, 0.0202, 0.0205,\n",
      "        0.0186, 0.0180, 0.0201, 0.0205, 0.0191, 0.0201, 0.0221, 0.0196, 0.0198,\n",
      "        0.0187, 0.0207, 0.0214, 0.0211, 0.0174, 0.0236, 0.0186, 0.0191, 0.0208,\n",
      "        0.0211, 0.0194, 0.0213, 0.0202, 0.0193, 0.0198, 0.0226, 0.0186, 0.0201,\n",
      "        0.0194, 0.0207, 0.0215, 0.0184, 0.0177], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0255, 0.0169, 0.0238, 0.0216, 0.0192, 0.0129, 0.0150, 0.0137, 0.0225,\n",
      "        0.0232, 0.0230, 0.0166, 0.0208, 0.0221, 0.0211, 0.0197, 0.0147, 0.0105,\n",
      "        0.0145, 0.0129, 0.0201, 0.0222, 0.0125, 0.0196, 0.0358, 0.0204, 0.0155,\n",
      "        0.0172, 0.0265, 0.0167, 0.0279, 0.0226, 0.0325, 0.0175, 0.0125, 0.0202,\n",
      "        0.0223, 0.0207, 0.0346, 0.0149, 0.0187, 0.0176, 0.0200, 0.0149, 0.0205,\n",
      "        0.0154, 0.0292, 0.0305, 0.0142, 0.0164], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0283, 0.0148, 0.0242, 0.0195, 0.0174, 0.0079, 0.0108, 0.0080, 0.0237,\n",
      "        0.0254, 0.0248, 0.0123, 0.0187, 0.0235, 0.0202, 0.0187, 0.0096, 0.0048,\n",
      "        0.0106, 0.0086, 0.0187, 0.0226, 0.0074, 0.0189, 0.0602, 0.0206, 0.0105,\n",
      "        0.0143, 0.0342, 0.0126, 0.0357, 0.0261, 0.0431, 0.0157, 0.0076, 0.0187,\n",
      "        0.0224, 0.0211, 0.0557, 0.0104, 0.0175, 0.0132, 0.0173, 0.0098, 0.0203,\n",
      "        0.0107, 0.0374, 0.0420, 0.0104, 0.0130], grad_fn=<SoftmaxBackward0>)\n",
      "Actions: [14, 31, 41, 21, 37, 14, 9, 3, 40, 15, 6, 20, 33, 38, 2, 42, 30, 14, 49, 36, 15, 4, 7, 7, 46] Return: 162951.859375\n",
      "Best payoff: 171613.796875 Best actions: tensor([32, 40, 41,  9, 48, 21, 24, 32, 22,  0, 48, 40, 39, 49, 28, 25, 23, 48,\n",
      "        26, 38, 36, 25, 42, 38, 24])\n",
      "Batch: 0 Batch return: 165852.65359375\n",
      "Best payoff: 172697.984375 Best actions: tensor([ 0, 37,  6, 40, 26, 42, 44, 46, 41, 31, 49, 38, 36, 28, 46, 46, 32, 49,\n",
      "        37, 40, 32, 44, 10, 46, 36])\n",
      "Best payoff: 173768.140625 Best actions: tensor([32, 21, 44, 34, 29, 31, 42, 49, 40, 44, 24, 35, 47, 24, 45, 39, 36, 32,\n",
      "        46, 24, 12,  4, 36, 42, 21])\n",
      "Batch: 10 Batch return: 166350.27359375\n",
      "Batch: 20 Batch return: 167322.42578125\n",
      "Best payoff: 174585.25 Best actions: tensor([47, 31, 20, 47, 39, 44, 33, 45, 30, 27, 45, 15, 24, 28, 32, 42, 49, 44,\n",
      "        38, 31, 47, 23, 24, 36, 30])\n",
      "Best payoff: 174840.453125 Best actions: tensor([35, 30, 36, 48, 33, 37, 41, 28, 33, 28, 35, 42, 45,  8, 25, 38, 38, 26,\n",
      "        41, 43, 44, 31, 32, 32, 30])\n",
      "Batch: 30 Batch return: 168351.401875\n",
      "Best payoff: 176461.8125 Best actions: tensor([49, 21, 32, 26, 43, 44, 32, 34, 44, 39, 38, 44, 38, 26, 24, 47, 47, 36,\n",
      "        44, 36, 32, 46, 32, 39, 18])\n",
      "Batch: 40 Batch return: 169216.07921875\n",
      "Best payoff: 176691.25 Best actions: tensor([34, 44, 21, 24, 49, 47, 47, 43, 28, 38, 40, 31, 42, 32, 43, 38, 38, 31,\n",
      "        46, 46, 47, 42, 31, 32, 29])\n",
      "tensor([0.0179, 0.0170, 0.0205, 0.0193, 0.0177, 0.0173, 0.0169, 0.0173, 0.0192,\n",
      "        0.0185, 0.0168, 0.0190, 0.0194, 0.0189, 0.0202, 0.0200, 0.0200, 0.0188,\n",
      "        0.0186, 0.0170, 0.0204, 0.0214, 0.0186, 0.0200, 0.0224, 0.0203, 0.0203,\n",
      "        0.0191, 0.0219, 0.0228, 0.0211, 0.0191, 0.0251, 0.0183, 0.0195, 0.0228,\n",
      "        0.0224, 0.0204, 0.0234, 0.0218, 0.0204, 0.0205, 0.0242, 0.0185, 0.0228,\n",
      "        0.0194, 0.0218, 0.0231, 0.0197, 0.0182], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0075, 0.0051, 0.0081, 0.0054, 0.0049, 0.0033, 0.0042, 0.0024, 0.0105,\n",
      "        0.0074, 0.0077, 0.0075, 0.0119, 0.0123, 0.0130, 0.0081, 0.0076, 0.0038,\n",
      "        0.0090, 0.0070, 0.0177, 0.0182, 0.0066, 0.0112, 0.0440, 0.0225, 0.0114,\n",
      "        0.0093, 0.0425, 0.0275, 0.0299, 0.0667, 0.0565, 0.0133, 0.0101, 0.0307,\n",
      "        0.0295, 0.0260, 0.1059, 0.0204, 0.0211, 0.0138, 0.0299, 0.0140, 0.0515,\n",
      "        0.0100, 0.0371, 0.0479, 0.0131, 0.0153], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.3153e-03, 7.4168e-04, 1.4398e-03, 6.7764e-04, 5.8967e-04, 2.7560e-04,\n",
      "        4.2952e-04, 1.2792e-04, 2.8255e-03, 1.3825e-03, 1.5074e-03, 1.3439e-03,\n",
      "        3.2727e-03, 3.8327e-03, 4.1367e-03, 1.6917e-03, 1.3810e-03, 3.2560e-04,\n",
      "        2.1464e-03, 1.3800e-03, 7.6176e-03, 8.2166e-03, 1.0946e-03, 3.3053e-03,\n",
      "        4.8267e-02, 1.3927e-02, 3.1319e-03, 2.1484e-03, 4.9455e-02, 1.8180e-02,\n",
      "        2.2559e-02, 1.2980e-01, 7.0938e-02, 4.9877e-03, 2.5308e-03, 2.3977e-02,\n",
      "        2.0875e-02, 1.8238e-02, 2.9533e-01, 1.0003e-02, 1.1945e-02, 4.1320e-03,\n",
      "        2.0858e-02, 5.1870e-03, 7.0531e-02, 2.3517e-03, 3.2881e-02, 5.5573e-02,\n",
      "        4.7688e-03, 6.3668e-03], grad_fn=<SoftmaxBackward0>)\n",
      "Actions: [7, 14, 48, 41, 31, 38, 16, 12, 5, 32, 38, 30, 13, 40, 37, 42, 9, 42, 38, 38, 28, 26, 29, 38, 47] Return: 167905.890625\n",
      "Batch: 50 Batch return: 170310.56140625\n",
      "Batch: 60 Batch return: 170974.2590625\n",
      "Best payoff: 177001.8125 Best actions: tensor([26, 36, 41, 47, 25, 42, 47, 47, 38, 38, 46, 31, 44, 40, 32, 24, 38, 32,\n",
      "        38, 38, 44, 28, 47, 38, 14])\n",
      "Best payoff: 177159.5 Best actions: tensor([31, 34, 36, 25, 42, 39, 31, 37, 38, 46, 40, 38, 48, 40, 47, 32, 38, 28,\n",
      "        47, 38, 38, 38, 38, 38, 24])\n",
      "Batch: 70 Batch return: 172327.0046875\n",
      "Batch: 80 Batch return: 173255.70328125\n",
      "Best payoff: 177201.375 Best actions: tensor([47, 44, 33, 35, 26, 33, 44, 38, 44, 42, 47, 38, 29, 32, 30, 35, 38, 38,\n",
      "        38, 44, 38, 38, 38, 38, 21])\n",
      "Batch: 90 Batch return: 174420.5\n",
      "Best payoff: 177506.359375 Best actions: tensor([44, 43, 44, 38, 45, 38, 47, 48, 38, 38, 38, 38, 38, 38, 44, 38, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38])\n",
      "Best payoff: 177835.5625 Best actions: tensor([46, 40, 37, 44, 46, 33, 46, 44, 44, 44, 46, 38, 47, 42, 47, 44, 38, 38,\n",
      "        38, 38, 38, 38, 38, 38, 38])\n",
      "tensor([0.0118, 0.0119, 0.0147, 0.0139, 0.0129, 0.0116, 0.0118, 0.0109, 0.0154,\n",
      "        0.0148, 0.0121, 0.0138, 0.0161, 0.0150, 0.0168, 0.0163, 0.0166, 0.0137,\n",
      "        0.0156, 0.0134, 0.0198, 0.0206, 0.0158, 0.0181, 0.0218, 0.0204, 0.0182,\n",
      "        0.0173, 0.0244, 0.0256, 0.0217, 0.0233, 0.0334, 0.0192, 0.0205, 0.0288,\n",
      "        0.0285, 0.0234, 0.0401, 0.0274, 0.0231, 0.0212, 0.0325, 0.0181, 0.0344,\n",
      "        0.0187, 0.0266, 0.0327, 0.0246, 0.0205], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([7.0119e-05, 5.0633e-05, 1.0734e-04, 6.2589e-05, 5.8379e-05, 2.1070e-05,\n",
      "        4.0181e-05, 1.1061e-05, 2.3189e-04, 1.1252e-04, 1.3550e-04, 9.2412e-05,\n",
      "        3.0254e-04, 2.3774e-04, 3.1530e-04, 2.0194e-04, 1.5733e-04, 4.7977e-05,\n",
      "        1.9193e-04, 1.5930e-04, 9.1086e-04, 1.0112e-03, 1.6412e-04, 5.3971e-04,\n",
      "        3.3431e-03, 2.2523e-03, 4.3770e-04, 4.4099e-04, 9.0325e-03, 4.5413e-03,\n",
      "        3.6638e-03, 2.2001e-02, 2.2062e-02, 2.0963e-03, 1.2777e-03, 9.9356e-03,\n",
      "        1.1584e-02, 6.5480e-03, 7.1965e-01, 7.0062e-03, 5.1203e-03, 1.8594e-03,\n",
      "        1.7449e-02, 1.6136e-03, 8.2476e-02, 5.8411e-04, 1.3893e-02, 3.9361e-02,\n",
      "        3.6858e-03, 2.8549e-03], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([7.7004e-09, 4.6623e-09, 1.5924e-08, 5.9179e-09, 5.5629e-09, 7.1195e-10,\n",
      "        2.5921e-09, 1.7298e-10, 8.6572e-08, 2.0450e-08, 3.0013e-08, 1.3155e-08,\n",
      "        1.3687e-07, 9.7149e-08, 1.5680e-07, 6.9228e-08, 3.5815e-08, 3.4872e-09,\n",
      "        6.2735e-08, 4.5895e-08, 1.3326e-06, 1.5539e-06, 4.4603e-08, 5.0062e-07,\n",
      "        1.8041e-05, 9.0972e-06, 2.9896e-07, 3.2715e-07, 1.4255e-04, 3.5707e-05,\n",
      "        2.1749e-05, 9.1757e-04, 6.5380e-04, 7.9152e-06, 2.5484e-06, 1.6079e-04,\n",
      "        2.0373e-04, 7.8611e-05, 9.8267e-01, 7.6112e-05, 4.7018e-05, 5.0015e-06,\n",
      "        4.5721e-04, 4.4026e-06, 1.1635e-02, 5.1117e-07, 2.9186e-04, 2.5217e-03,\n",
      "        2.3010e-05, 1.4299e-05], grad_fn=<SoftmaxBackward0>)\n",
      "Actions: [12, 23, 26, 3, 25, 38, 44, 29, 28, 44, 32, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 46, 38, 38, 38] Return: 172949.890625\n",
      "Batch: 100 Batch return: 174949.2984375\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "neuralNet=NeuralNetwork(lr = 0.0001, num_input= 2, num_actions=50, nn_dim = 200)\n",
    "algorithm = ReinforceAlgorithm(game, neuralNet, numberBatches=201, numberEpiPerBatch=100)\n",
    "algorithm.solver()\n",
    "ft = time.time()\n",
    "print(\"Time:\", ft-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "learning = pd.DataFrame(algorithm.returns,columns=['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_2 = [0]*len(learning)\n",
    "for i in range(len(learning_2)):\n",
    "    learning_2[i] = learning[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learning_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_learning = np.convolve(learning_2, np.ones(1000)/1000, mode = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(avg_learning)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
