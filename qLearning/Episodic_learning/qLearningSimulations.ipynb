{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningAgent import LearningAlgorithm\n",
    "from environment import Model, AdversaryModes\n",
    "from Qtable import QTable\n",
    "from test import Test\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demand = 400\n",
    "agent_cost = 57\n",
    "adversary_cost = 71 \n",
    "costs = [agent_cost,adversary_cost]\n",
    "total_stages = 25\n",
    "initial_state = [total_demand/2, total_demand/2]\n",
    "adversary_probabilities=[0]*len(AdversaryModes)\n",
    "adversary_probabilities[10]=1 \n",
    "game = Model(total_demand, costs, total_stages, adversary_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_actions = 50\n",
    "number_demands = total_demand + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate is given as [numerator,denominator] which gives us a learning rate function of \n",
    "# numerator/(n+demoninator)\n",
    "Qtable = QTable(number_demands, number_actions, total_stages , learning_rate = [1000000,1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_episodes = 1_000_000\n",
    "discount_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = LearningAlgorithm(game, Qtable, number_episodes, discount_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250000\n",
      "500000\n",
      "750000\n",
      "124696\n",
      "124696\n",
      "124696\n"
     ]
    }
   ],
   "source": [
    "algorithm.solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113911.83, 114009.83, 114142.18, 114228.91, 114705.89, 114795.89,\n",
       "       114784.28, 114875.64, 115470.88, 115555.6 , 115793.71, 115871.71,\n",
       "       116099.54, 116173.23, 116515.16, 116585.15, 116680.51, 116746.51,\n",
       "       117124.79, 117186.79, 117251.72, 117251.93, 117368.36, 117438.03,\n",
       "       117952.62, 118002.65, 117871.09, 117917.09, 117905.87, 117947.87,\n",
       "       118067.29, 118086.84, 118379.51, 118413.51, 118214.4 , 118243.77,\n",
       "       118520.11, 118546.11, 118767.77, 118790.73, 118630.41, 118648.54,\n",
       "       118650.85, 118664.85, 118631.47, 118641.47, 118550.13, 118556.13,\n",
       "       118541.42, 118543.41])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qtable.Q_table[200, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22556608478802992"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(Qtable.Q_table) / (number_actions * number_demands * total_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_probabilities=[0]*len(AdversaryModes)\n",
    "adversary_probabilities[10]=1 # We can test the Q-Table against any strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Test(game, Qtable, discount_factor, adversary_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99478.0\n",
      "62067.0\n",
      "[118 132 107  99 110  97  91  94  98  86  91  77 104  80  90  99  83  95\n",
      "  85  93  84  95  94 112 122]\n",
      "[132 132 132  83  91  91  91  91  91  91  91  91  91  91  91  91  91  91\n",
      "  91  91  91  91  91  91 142]\n",
      "[200. 207. 207. 219. 211. 201. 198. 198. 196. 192. 194. 194. 201. 194.\n",
      " 199. 199. 195. 199. 197. 200. 199. 202. 200. 198. 187.]\n"
     ]
    }
   ],
   "source": [
    "# Returns the optimal payoff and actions according to the Qtable\n",
    "payoff, adversary_payoff, actions, adversary_actions, demand_potential = result.total_payoff()\n",
    "print(payoff)\n",
    "print(adversary_payoff)\n",
    "print(actions)\n",
    "print(adversary_actions)\n",
    "print(demand_potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n",
      "Div by zero error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.13327514527667506"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The percentage error of the Qtable. This has to be measured against the same opponent that \n",
    "# it was trained against, as this is a measure of how 'complete' the training is.\n",
    "result.error(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following calculates the payoff that the Q-Table gives against the different opponenets. \n",
    "# It may reach a state in which the Q-Table was not trained. This will cause an error saying \n",
    "# either 'max demand reached' or 'min demand reached'.\n",
    "# for i in range(len(AdversaryModes)):\n",
    "#     print(AdversaryModes(i))\n",
    "#     adversaryProbs=[0]*len(AdversaryModes)\n",
    "#     adversaryProbs[i]=1\n",
    "#     result = Test(game, Qtable, discountFactor, adversaryProbs)\n",
    "#     payoff, advPayoff, actions, advActions, demandPotential = result.totalPayoff()\n",
    "#     print(payoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
