{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningAgent import LearningAlgorithm\n",
    "from environment import Model, AdversaryModes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_Demand = 400\n",
    "tuple_Costs = [57,71]\n",
    "total_Stages = 25\n",
    "init_State = [total_Demand/2, total_Demand/2]\n",
    "adversary_Mode = AdversaryModes.myopic\n",
    "\n",
    "game = Model(total_Demand, tuple_Costs, total_Stages, init_State, adversary_Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_Cost = tuple_Costs[0]\n",
    "adv_Cost = tuple_Costs[1]\n",
    "num_Actions = 10\n",
    "num_States = abs(adv_Cost - agent_Cost) + 2 * num_Actions + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtable = np.zeros((num_States, num_Actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEpisodes = 10000\n",
    "discountFactor = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = LearningAlgorithm(game, Qtable, numberEpisodes, discountFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithm.solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Error\n",
    "Qtable_error = np.zeros((num_States, num_Actions))\n",
    "\n",
    "for s in range(num_States):\n",
    "    for a in range(num_Actions):\n",
    "        lowestState = int(200-(num_States)/2)\n",
    "        highestState = int(200+(num_States)/2 - 1)\n",
    "        state = s + lowestState\n",
    "\n",
    "        monopoly_price = int((state + agent_Cost)/2) + 1\n",
    "        action = a + monopoly_price - num_Actions + 1\n",
    "\n",
    "        reward = (state - action) * (action - agent_Cost)\n",
    "        adv_action = int((400 -state + adv_Cost)/2) + 1\n",
    "        next_state = int(state + (adv_action - action)/2)\n",
    "        #print(state,monopoly_price,action,reward,adv_action, next_state)\n",
    "\n",
    "        ns = next_state - lowestState\n",
    "        opt_value_next = max(Qtable[ns])\n",
    "        new_value = (1-discountFactor)*reward + discountFactor * opt_value_next\n",
    "        Qtable_error[s,a] = (new_value - Qtable[s,a])/new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03 0.03 0.06 0.03 0.01 0.03 0.03 0.02 0.01 0.  ]\n",
      " [0.01 0.01 0.01 0.02 0.02 0.03 0.01 0.01 0.03 0.01]\n",
      " [0.02 0.03 0.02 0.01 0.03 0.02 0.02 0.01 0.04 0.02]\n",
      " [0.   0.02 0.03 0.03 0.01 0.03 0.01 0.02 0.01 0.01]\n",
      " [0.02 0.01 0.03 0.   0.   0.03 0.04 0.01 0.03 0.03]\n",
      " [0.02 0.03 0.02 0.01 0.04 0.   0.08 0.05 0.01 0.01]\n",
      " [0.01 0.03 0.03 0.01 0.02 0.04 0.01 0.02 0.03 0.01]\n",
      " [0.01 0.02 0.01 0.02 0.01 0.06 0.08 0.01 0.04 0.04]\n",
      " [0.13 0.03 0.01 0.03 0.08 0.02 0.   0.06 0.01 0.03]\n",
      " [0.02 0.01 0.01 0.02 0.02 0.05 0.02 0.01 0.02 0.02]\n",
      " [0.   0.02 0.01 0.02 0.01 0.01 0.01 0.01 0.   0.06]\n",
      " [0.03 0.02 0.02 0.01 0.03 0.02 0.01 0.01 0.04 0.02]\n",
      " [0.02 0.   0.   0.02 0.02 0.03 0.02 0.05 0.01 0.02]\n",
      " [0.   0.01 0.06 0.02 0.03 0.04 0.05 0.02 0.05 0.02]\n",
      " [0.06 0.   0.   0.01 0.01 0.04 0.06 0.03 0.03 0.07]\n",
      " [0.03 0.04 0.01 0.04 0.02 0.01 0.04 0.02 0.12 0.02]\n",
      " [0.01 0.04 0.04 0.03 0.01 0.03 0.   0.02 0.05 0.04]\n",
      " [0.05 0.03 0.01 0.03 0.04 0.   0.03 0.   0.02 0.03]\n",
      " [0.03 0.02 0.04 0.03 0.03 0.   0.   0.01 0.01 0.01]\n",
      " [0.03 0.03 0.02 0.04 0.04 0.02 0.   0.01 0.05 0.03]\n",
      " [0.05 0.05 0.04 0.02 0.04 0.04 0.02 0.01 0.01 0.02]\n",
      " [0.01 0.03 0.05 0.04 0.04 0.06 0.05 0.03 0.04 0.05]\n",
      " [0.02 0.11 0.02 0.05 0.02 0.04 0.02 0.02 0.04 0.03]\n",
      " [0.03 0.02 0.09 0.04 0.04 0.03 0.04 0.05 0.02 0.02]\n",
      " [0.05 0.02 0.02 0.01 0.04 0.01 0.06 0.03 0.03 0.01]\n",
      " [0.   0.04 0.02 0.02 0.03 0.13 0.04 0.08 0.03 0.04]\n",
      " [0.02 0.   0.05 0.02 0.02 0.01 0.02 0.04 0.02 0.02]\n",
      " [0.02 0.   0.02 0.01 0.02 0.06 0.02 0.01 0.01 0.06]\n",
      " [0.04 0.07 0.01 0.04 0.01 0.02 0.02 0.01 0.02 0.08]\n",
      " [0.02 0.02 0.   0.01 0.01 0.01 0.03 0.02 0.05 0.05]\n",
      " [0.04 0.01 0.07 0.02 0.02 0.02 0.04 0.02 0.03 0.05]\n",
      " [0.01 0.01 0.01 0.03 0.03 0.   0.03 0.05 0.02 0.05]\n",
      " [0.01 0.03 0.02 0.05 0.   0.01 0.   0.02 0.03 0.01]\n",
      " [0.02 0.01 0.02 0.1  0.02 0.01 0.03 0.05 0.03 0.01]\n",
      " [0.01 0.01 0.04 0.05 0.02 0.07 0.01 0.01 0.01 0.03]\n",
      " [0.01 0.01 0.02 0.03 0.01 0.02 0.04 0.01 0.04 0.01]]\n"
     ]
    }
   ],
   "source": [
    "print(Qtable_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
