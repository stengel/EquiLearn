{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2260b9-103a-4e14-9637-c513c462c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import SAC, PPO\n",
    "import time\n",
    "from src.environments import ConPricingGame\n",
    "import src.globals as gl\n",
    "import src.classes as cl\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from typing import List, Dict\n",
    "from enum import Enum\n",
    "import json\n",
    "import logging\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='error.log', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6be8caa-d89e-42be-8c3c-49a529d4a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_params = {\n",
    "    'SAC': {\n",
    "        'learning_rate': 0.0003,\n",
    "        'target_entropy': 'auto',\n",
    "        'ent_coef': 'auto',\n",
    "        'tau': 0.010,\n",
    "        'train_freq': 1,\n",
    "        'gradient_steps': 1,\n",
    "        'verbose': 0,\n",
    "        'buffer_size': 200_000\n",
    "    },\n",
    "    'PPO': {\n",
    "        'learning_rate': 0.00016,\n",
    "        'n_epochs': 10,\n",
    "        'clip_range': 0.3,\n",
    "        'clip_range_vf': None,\n",
    "        'ent_coef': 0.010,\n",
    "        'vf_coef': 0.5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class ProcessInd(Enum):\n",
    "    SAClow = 0\n",
    "    PPOlow = 1\n",
    "    SAChigh = 2\n",
    "    PPOhigh = 3\n",
    "\n",
    "\n",
    "class StartMode(Enum):\n",
    "    \"\"\" double oracle game strting point, start from myopic-const-guess or from a random model or different strategies similar to guess\"\"\"\n",
    "    myopicConstGuess = 0\n",
    "    random = 1\n",
    "    multiGuess = 2\n",
    "    allVsSpe=3\n",
    "    \n",
    "def len_initial_game(start_mode:StartMode)->int:\n",
    "    if start_mode==StartMode.myopicConstGuess or start_mode==StartMode.multiGuess:\n",
    "        return 3\n",
    "    elif start_mode==StartMode.random:\n",
    "        return 1\n",
    "    elif start_mode==StartMode.allVsSpe:\n",
    "        return 7\n",
    "    else:\n",
    "        raise ValueError(\"len of start_mode not implemented!\")\n",
    "        \n",
    "    \n",
    "def remove_ineffective_agents(bimatrix_game:cl.BimatrixGame, db:cl.DataBase, start_mode:StartMode):\n",
    "    \"\"\" according to average_probs table, removes that have never been part of an equilibrium, and they have been in the game for a while, also updates the added column of agents to -1, and the pickle file and game should be saved again\"\"\"\n",
    "    query=f\"select * from {db.PROBS_TABLE} order by id desc limit 1;\"\n",
    "    df= db.dataframe_select(query=query)\n",
    "    if df.empty:\n",
    "        return bimatrix_game\n",
    "    row = df.iloc[0]\n",
    "    \n",
    "    \n",
    "    probs = json.loads(row['strategy_probs'])\n",
    "    start_ind=len_initial_game(start_mode=start_mode)\n",
    "    #########to be done\n",
    "\n",
    "\n",
    "def initial_matrix(env_class, start_mode):\n",
    "    \"\"\" returns double oracle game with strategies from last stopping point but the matrix and strategies are not loaded , creates the base matrix and adds the trained strategies\"\"\"\n",
    "    if start_mode == StartMode.myopicConstGuess:\n",
    "\n",
    "        strt1 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.myopic, name=\"myopic\")\n",
    "        strt2 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.const, name=\"const\", first_price=132)\n",
    "        strt3 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess, name=\"guess\", first_price=132)\n",
    "\n",
    "        init_low = [strt1, strt2, strt3]\n",
    "        init_high = [strt1, strt2, strt3]\n",
    "    elif start_mode == StartMode.allVsSpe:\n",
    "        strt0 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.spe, name=\"spe\", first_price=132)\n",
    "        strt1 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.myopic, name=\"myopic\")\n",
    "        strt2 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.const, name=\"const\", first_price=132)\n",
    "        strt3 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.imit, name=\"imit\", first_price=132)\n",
    "        \n",
    "        strt4 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess, name=\"normal_guess\",first_price=132)\n",
    "        strt5 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess2, name=\"coop_guess\", first_price=132)\n",
    "        strt6 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess3, name=\"compete_guess\", first_price=132)\n",
    "\n",
    "        init_low = [strt0,strt1, strt2, strt3,strt4,strt5,strt6]\n",
    "        init_high = [strt0,strt1, strt2, strt3,strt4,strt5,strt6]\n",
    "    elif start_mode == StartMode.random:\n",
    "        model_name = f\"rndstart_{job_name}\"\n",
    "        log_dir = f\"{gl.LOG_DIR}/{model_name}\"\n",
    "        model_dir = f\"{gl.MODELS_DIR}/{model_name}\"\n",
    "        if not os.path.exists(f\"{model_dir}.zip\"):\n",
    "            # tuple_costs and others are none just to make sure no play is happening here\n",
    "            train_env = env_class(tuple_costs=None, adversary_mixed_strategy=None, memory=gl.MEMORY)\n",
    "            model = SAC('MlpPolicy', train_env,\n",
    "                        verbose=0, tensorboard_log=log_dir, gamma=gl.GAMMA, target_entropy=0)\n",
    "            model.save(model_dir)\n",
    "\n",
    "        strt_rnd = cl.Strategy(strategy_type=cl.StrategyType.sb3_model,\n",
    "                               model_or_func=SAC, name=model_name, action_step=None, memory=gl.MEMORY)\n",
    "\n",
    "        init_low = [strt_rnd]\n",
    "        init_high = [strt_rnd]\n",
    "    elif start_mode==StartMode.multiGuess:\n",
    "        strt1 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess, name=\"normal_guess\",first_price=132)\n",
    "        strt2 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess2, name=\"coop_guess\", first_price=132)\n",
    "        strt3 = cl.Strategy(\n",
    "            cl.StrategyType.static, model_or_func=cl.guess3, name=\"compete_guess\", first_price=132)\n",
    "\n",
    "        init_low = [strt1, strt2, strt3]\n",
    "        init_high = [strt1, strt2, strt3]\n",
    "    else:\n",
    "        raise(\"Error: initial_matrix mode not implemented!\")\n",
    "    \n",
    "\n",
    "    low_strts, high_strts = db.get_list_of_added_strategies(action_step=None, memory=gl.MEMORY)\n",
    "    return cl.BimatrixGame(\n",
    "        low_cost_strategies=init_low+low_strts, high_cost_strategies=init_high+high_strts, env_class=env_class)\n",
    "\n",
    "\n",
    "def get_proc_input(seed, proc_ind: ProcessInd, low_mixed_strt, high_mixed_strt, payoffs_low_high, job_name, env_class,num_ep_coef,equi_id) -> cl.TrainInputRow:\n",
    "    \"\"\"\n",
    "    creates the input tuple for new_train method, to use in multiprocessing\n",
    "    \"\"\"\n",
    "    # input=(id, seed, job_name, env, base_agent, alg, alg_params, adv_mixed_strategy,target_payoff, db)\n",
    "    if proc_ind == ProcessInd.PPOlow or proc_ind == ProcessInd.SAClow:\n",
    "        costs = [gl.LOW_COST, gl.HIGH_COST]\n",
    "        own_strt = low_mixed_strt.copy_unload()\n",
    "        adv_strt = high_mixed_strt.copy_unload()\n",
    "        payoff = payoffs_low_high[0]\n",
    "    elif proc_ind == ProcessInd.PPOhigh or proc_ind == ProcessInd.SAChigh:\n",
    "        costs = [gl.HIGH_COST, gl.LOW_COST]\n",
    "        own_strt = high_mixed_strt.copy_unload()\n",
    "        adv_strt = low_mixed_strt.copy_unload()\n",
    "        payoff = payoffs_low_high[1]\n",
    "\n",
    "    if proc_ind == ProcessInd.SAChigh or proc_ind == ProcessInd.SAClow:\n",
    "        alg = SAC\n",
    "    elif proc_ind == ProcessInd.PPOhigh or proc_ind == ProcessInd.PPOlow:\n",
    "        alg = PPO\n",
    "\n",
    "    iid = proc_ind.value\n",
    "    env = env_class(tuple_costs=costs, adversary_mixed_strategy=adv_strt, memory=gl.MEMORY)\n",
    "    base_agent = cl.find_base_agent(db, alg, costs[0], own_strt)\n",
    "    return cl.TrainInputRow(iid, seed+iid, job_name, env, base_agent, alg, alg_params[cl.name_of(alg)], adv_strt, payoff, db,num_ep_coef,equi_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d7207-348a-47b0-b8a8-dddbf94bbe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1 equi: [0], [0]\n",
      " payoffs= 107.01, 61.79\n",
      "round 2 equi: [1], [0]\n",
      " payoffs= 113.83, 59.80\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gl.initialize()\n",
    "\n",
    "    env_class = ConPricingGame\n",
    "\n",
    "    num_rounds = 50\n",
    "    num_procs = 7\n",
    "    # works best with num_process=1 or >=4\n",
    "    start_mode = StartMode.random\n",
    "    job_name = \"Jun11_rnd\"\n",
    "\n",
    "    db_name = job_name+\".db\"\n",
    "    db = cl.DataBase(db_name)\n",
    "    cl.set_job_name(job_name)\n",
    "    cl.create_directories()\n",
    "    equis_id_dict = []\n",
    "\n",
    "    start_game = initial_matrix(env_class=env_class, start_mode=start_mode)\n",
    "\n",
    "    bimatrix_game = cl.load_latest_game(game_data_name=f\"game_{job_name}\", new_game=start_game)\n",
    "\n",
    "    cl.prt(\"\\n\" + time.ctime(time.time())+\"\\n\"+(\"-\"*50)+\"\\n\")\n",
    "\n",
    "    equis_id_dict = cl.get_coop_equilibria(bimatrix_game=bimatrix_game, num_trace=100, db=db)\n",
    "    game_size = bimatrix_game.size()\n",
    "    \n",
    "    #coeficient of how much num_episodes should be increased\n",
    "    num_ep_coef=1\n",
    "    \n",
    "    # db.delete_extra_rows(db.ITERS_TABLE, 'agent_id', gl.DB_ITER_LIMIT)\n",
    "\n",
    "    # low_cost_probabilities, high_cost_probabilities, low_cost_payoff, high_cost_payoff = bimatrix_game.compute_equilibria()\n",
    "    for round in range(num_rounds):\n",
    "        cl.prt(f\"\\n\\tRound {round+1} of {num_rounds}\")\n",
    "\n",
    "        added_low = 0\n",
    "        added_high = 0\n",
    "        # for equilibrium in dictionaries:\n",
    "        for equi in equis_id_dict:\n",
    "\n",
    "            db.updates_equi_average_probs(equis_id_dict[equi], equi)\n",
    "            new_equi_low = 0\n",
    "            new_equi_high = 0\n",
    "            print(\n",
    "                f'round {round+1} equi: {str(equi.row_support)}, {str(equi.col_support)}\\n payoffs= {equi.row_payoff:.2f}, {equi.col_payoff:.2f}')\n",
    "            cl.prt(\n",
    "                f'equi: {str(equi.row_support)}, {str(equi.col_support)}\\n payoffs= {equi.row_payoff:.2f}, {equi.col_payoff:.2f}')\n",
    "\n",
    "            # train a low-cost agent\n",
    "            high_mixed_strat = cl.MixedStrategy(\n",
    "                strategies_lst=bimatrix_game.high_strategies, probablities_lst=((equi.col_probs+([0]*added_high)) if\n",
    "                                                                                added_high > 0 else equi.col_probs))\n",
    "            low_mixed_strat = cl.MixedStrategy(\n",
    "                strategies_lst=bimatrix_game.low_strategies, probablities_lst=((equi.row_probs+([0]*added_low)) if added_low > 0 else equi.row_probs))\n",
    "\n",
    "            # prepare processes\n",
    "            proc_inputs = []\n",
    "            input_id_dict: Dict[int, cl.TrainInputRow] = {}\n",
    "            seed = int(time.time())\n",
    "            for proc_ind in ProcessInd:\n",
    "                inp = get_proc_input(seed, proc_ind, low_mixed_strat, high_mixed_strat, [\n",
    "                                    equi.row_payoff, equi.col_payoff], job_name, env_class,num_ep_coef,equis_id_dict[equi])\n",
    "                proc_inputs.append(inp)\n",
    "                input_id_dict[inp.id] = inp\n",
    "\n",
    "            if num_procs > 1:\n",
    "                if (extra_prcs := num_procs-len(ProcessInd)) > 0:\n",
    "                    for ext_ind in range(extra_prcs):\n",
    "                        # choose a random processInd to be done with the extra core\n",
    "                        new_proc_ind = np.random.choice(list(ProcessInd))\n",
    "                        new_seed = seed+1 + (ext_ind+1) * len(ProcessInd)\n",
    "                        inp = get_proc_input(new_seed, new_proc_ind, low_mixed_strat, high_mixed_strat, [\n",
    "                                            equi.row_payoff, equi.col_payoff], job_name, env_class,num_ep_coef,equis_id_dict[equi])\n",
    "                        proc_inputs.append(inp)\n",
    "                        input_id_dict[inp.id] = inp\n",
    "                pool = mp.Pool(processes=num_procs)\n",
    "                outputs = pool.imap_unordered(cl.new_train, proc_inputs)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "            else:\n",
    "                outputs = []\n",
    "                for inp in proc_inputs:\n",
    "                    outputs.append(cl.new_train(inp))\n",
    "                    input_id_dict[inp.id] = inp\n",
    "\n",
    "            for output in outputs:\n",
    "                id, acceptable, strategy_name, agent_payoffs, adv_payoffs, expected_payoff = output\n",
    "                inp = input_id_dict[id]\n",
    "\n",
    "            # id,acceptable,strategy_name,agent_payoffs, adv_payoffs, expected_payoff= train(inputs[0])\n",
    "                # pricing_game = env_class(tuple_costs=costs, adversary_mixed_strategy=adv_strt, memory=memory)\n",
    "                pricing_game = inp.env\n",
    "                model_strategy = cl.Strategy(strategy_type=cl.StrategyType.sb3_model,\n",
    "                                            model_or_func=inp.alg, name=strategy_name, action_step=pricing_game.action_step, memory=pricing_game.memory)\n",
    "            # compute the payoff against all adv strategies, to be added to the matrix\n",
    "                if acceptable:\n",
    "                    updated_adv_strategy, agent_payoffs, adv_payoffs = cl.match_updated_size(\n",
    "                        bimatrix_game, inp.adv_mixed_strategy, pricing_game.costs[0], agent_payoffs, adv_payoffs)\n",
    "                    for strategy_index in range(len(updated_adv_strategy.strategies)):\n",
    "                        if updated_adv_strategy.strategy_probs[strategy_index] == 0:\n",
    "                            payoffs = []\n",
    "                            for _ in range(gl.NUM_STOCHASTIC_ITER):\n",
    "                                payoffs.append(model_strategy.play_against(\n",
    "                                    env=pricing_game, adversary=updated_adv_strategy.strategies[strategy_index]))\n",
    "                            mean_payoffs = np.array(payoffs).mean(axis=0)\n",
    "\n",
    "                            agent_payoffs[strategy_index] = mean_payoffs[0]\n",
    "                            adv_payoffs[strategy_index] = mean_payoffs[1]\n",
    "                    # results.append((acceptable, agent_payoffs, adv_payoffs, model_strategy, expected_payoff, inp.base_agent))\n",
    "                    if pricing_game.costs[0] == gl.LOW_COST:\n",
    "                        new_equi_low += 1\n",
    "                        added_low += 1\n",
    "                        bimatrix_game.low_strategies.append(model_strategy)\n",
    "                        bimatrix_game.add_low_cost_row(agent_payoffs, adv_payoffs)\n",
    "                        cl.prt(\n",
    "                            f'low-cost player {model_strategy.name} , payoff= {expected_payoff:.2f} added, base={inp.base_agent} ,alg={cl.name_of(inp.alg)}')\n",
    "                    elif pricing_game.costs[0] == gl.HIGH_COST:\n",
    "                        new_equi_high += 1\n",
    "                        added_high += 1\n",
    "                        bimatrix_game.high_strategies.append(model_strategy)\n",
    "                        bimatrix_game.add_high_cost_col(adv_payoffs, agent_payoffs)\n",
    "\n",
    "                        cl.prt(\n",
    "                            f'high-cost player {model_strategy.name} , payoff= {expected_payoff:.2f} added, base={inp.base_agent} ,alg={cl.name_of(inp.alg)}')\n",
    "\n",
    "            db.update_equi(id=equis_id_dict[equi], used=(new_equi_low > 0 or new_equi_high > 0),\n",
    "                        num_new_low=new_equi_low, num_new_high=new_equi_high)\n",
    "\n",
    "            # because high_mixed_strt is defined before the changes to bimatrix.high_strategies. (error in str(high_mixed))\n",
    "            if new_equi_high > 0:\n",
    "                high_mixed_strat.strategy_probs += [0]*new_equi_high\n",
    "\n",
    "            # if new_equi_low>0 or new_equi_high>0:\n",
    "                # equilibria.append(\n",
    "                #     [equi[\"low_cost_probs\"], equi[\"high_cost_probs\"], equi[\"low_cost_payoff\"], equi[\"high_cost_payoff\"]])\n",
    "                # to do: add the equilibria to the db\n",
    "            # db.insert_new_equi(game_size=game_size, low_strategy_txt=str(low_mixed_strat), high_strategy_txt=str(\n",
    "            #     high_mixed_strat), low_payoff=equi.row_payoff, high_payoff=equi.col_payoff, low_new_num=new_equi_low, high_new_num=new_equi_high)\n",
    "\n",
    "        if added_low == 0 and added_high == 0:\n",
    "            num_ep_coef *= gl.EPISODE_INCREASE_COEF\n",
    "        else:\n",
    "            equis_id_dict = cl.get_coop_equilibria(bimatrix_game=bimatrix_game, num_trace=100, db=db)\n",
    "            game_size = bimatrix_game.size()\n",
    "            num_ep_coef=1\n",
    "\n",
    "    all_equilibria = bimatrix_game.compute_equilibria()\n",
    "    equis_id_dict = all_equilibria[:min(len(all_equilibria), gl.NUM_TRACE_EQUILIBRIA)]\n",
    "except Exception as e:\n",
    "    # Log the error\n",
    "    logging.error(\"An error occurred: %s\", str(e))\n",
    "    # You can also print the error if needed\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd0969-65fe-4bc3-a0f0-8c559381d7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv2",
   "language": "python",
   "name": "condaenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
